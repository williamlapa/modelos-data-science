{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data - Curso DATACAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "duplicates = ride_sharing.duplicated('ride_id', keep= False)\n",
    "\n",
    "# Sort your duplicated rides\n",
    "duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')\n",
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "print(duplicated_rides[['ride_id', 'duration', 'user_birth_year']])\n",
    "\n",
    "# Drop complete duplicates from ride_sharing\n",
    "ride_dup = ride_sharing.drop_duplicates()\n",
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
    "\n",
    "# Find duplicated values again\n",
    "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "assert duplicated_rides.shape[0] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscando dados inconsistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "# buscando os dados que estão na coluna cleanlines do df airlines e que NÃO estão no domínio categories\n",
    "# Aqui é mostrado apenas os dados\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "# define AS LINHAS onde os dados estão inconsistentes\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "# Mostra as linhas completas onde há diferença entre o df e o categories (referência)\n",
    "print(airlines[cat_clean_rows])\n",
    "\n",
    "# Print rows with consistent categories only\n",
    "# Mostra apenas as linhas com dados CONSISTENTES (ao contrário do consistente)\n",
    "print(airlines[~cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizar (Replace Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando Regex e substituindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"-\" with nothing\n",
    "phones[\"Phone number\"] = phones[\"Phone number\"].str.replace(\"-\", \"\")\n",
    "\n",
    "# Replace phone numbers with lower than 10 digits to NaN\n",
    "digits = phones['Phone number'].str.len()\n",
    "phones.loc[digits < 10, \"Phone number\"] = np.nan\n",
    "\n",
    "# Find length of each row in Phone number column\n",
    "sanity_check = phone['Phone number'].str.len()\n",
    "# Assert minmum phone number length is 10\n",
    "assert sanity_check.min() >= 10\n",
    "# Assert all numbers do not have \"+\" or \"-\"\n",
    "assert phone['Phone number'].str.contains(\"+|-\").any() == False\n",
    "\n",
    "# Remember, assert returns nothing if the condition passes\n",
    "\n",
    "# REGEX - Replace letters with nothing USANDO REGEX\n",
    "phones['Phone number'] = phones['Phone number'].str.replace(r'\\D+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniformity - Conversão de dados (Datas e demais situações)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find values of acct_cur that are equal to 'euro'\n",
    "acct_eu = banking['acct_cur'] == 'euro'\n",
    "\n",
    "# Convert acct_amount where it is in euro to dollars\n",
    "# nesse caso ele busca o match acct_eu (já definido acima) na coluna 'acct_amount'\n",
    "banking.loc[acct_eu, 'acct_amount'] = banking.loc[acct_eu, 'acct_amount'] * 1.1 \n",
    "\n",
    "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "banking.loc[acct_eu, 'acct_cur'] = 'dollar'\n",
    "\n",
    "# Assert that only dollar currency remains\n",
    "assert banking['acct_cur'].unique() == 'dollar'\n",
    "\n",
    "# Print the header of account_opend\n",
    "print(banking['account_opened'].head())\n",
    "\n",
    "# Convert account_opened to datetime\n",
    "# Força a conversão de datas quando não encontra uma data válida (mês maior que 12 ou dias maior que 31)\n",
    "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
    "                                          # Infer datetime format\n",
    "                                          infer_datetime_format = True,\n",
    "                                          # Return missing value for error\n",
    "                                          errors = 'coerce') \n",
    "\n",
    "# Get year of account opened\n",
    "# Converte a coluna em formato ano\n",
    "banking['acct_year'] = banking['account_opened'].dt.strftime('%Y')\n",
    "\n",
    "# Print acct_year\n",
    "print(banking.acct_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation - Uma forma de verificar consistência a partir de soma ou agrupamento de colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Store fund columns to sum against\n",
    "# Define as colunas para somar\n",
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']\n",
    "\n",
    "# Find rows where fund_columns row sum == inv_amount\n",
    "# compara colunas somadas (usar axis = 1 para somar colunas) com outra coluna\n",
    "inv_equ = banking[fund_columns].sum(axis = 1) == banking['inv_amount']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "# o que for consistente e inconsistente separa\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])\n",
    "\n",
    "# Mesmo exemplo com datas de aniversário\n",
    "# Store today's date and find ages\n",
    "# Store today's date and find ages\n",
    "today = dt.date.today()\n",
    "ages_manual = today.year - banking['birth_date'].dt.year\n",
    "\n",
    "# Find rows where age column == ages_manual\n",
    "age_equ = banking['age'] == ages_manual\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando Valores Faltantes\n",
    "#IMportar dados e analisar missing valores usando biblioetaca Missingno\n",
    "\n",
    "import missingno as msno #biblioteca missingno - bem interessante\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Print number of missing values in banking\n",
    "print(banking.isna().sum())\n",
    "\n",
    "# Visualize missingness matrix\n",
    "msno.matrix(banking)\n",
    "plt.show()\n",
    "\n",
    "# Isolate missing and non missing values of inv_amount\n",
    "missing_investors = banking[banking['inv_amount'].isna()]\n",
    "investors = banking[~banking['inv_amount'].isna()]\n",
    "\n",
    "# Sort banking by age and visualize\n",
    "banking_sorted = banking.sort_values(by='age')\n",
    "msno.matrix(banking_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo valores faltantes:\n",
    "# Drop missing values of cust_id\n",
    "banking_fullid = banking.dropna(subset = ['cust_id'])\n",
    "\n",
    "# Compute estimated acct_amount\n",
    "acct_imp = banking_fullid['inv_amount']*5\n",
    "\n",
    "# Impute missing acct_amount with corresponding acct_imp\n",
    "banking_imputed = banking_fullid.fillna({'acct_amount':acct_imp})\n",
    "\n",
    "# Print number of missing values\n",
    "print(banking_imputed.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lógica Fuzzy para achar similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import process\n",
    "from thefuzz import process\n",
    "\n",
    "# Importing DataFrame\n",
    "restaurants = pd.read_csv('restaurants_L2')\n",
    "\n",
    "# Define string and array of possible matches\n",
    "categories = pd.Series(['italian', 'asian','american'])\n",
    "\n",
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "# Iterate through the list of matches to italian\n",
    "for match in matches:\n",
    "  # Check whether the similarity score is greater than or equal to 80\n",
    "  if  match[1] >= 80:\n",
    "    # Select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "    restaurants.loc[restaurants['cuisine_type'] == match[0]] = 'italian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semelhante às junções, a vinculação de registros (Record Linkage) é o ato de vincular dados de diferentes fontes em relação à mesma entidade. Mas, ao contrário das junções, a vinculação de registros não requer correspondências exatas entre diferentes pares de dados e, em vez disso, pode encontrar correspondências próximas usando a semelhança de cadeia de caracteres. É por isso que a vinculação de registros é eficaz quando não há chaves exclusivas comuns entre as fontes de dados nas quais você pode confiar ao vincular fontes de dados, como um identificador exclusivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo com Dataframe que não está neste notebook\n",
    "# Import recordlinkage\n",
    "import recordlinkage\n",
    "\n",
    "# Create indexing object\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Generate pairs blocked on state\n",
    "indexer.block('state')\n",
    "pairs = indexer.index(census_A, census_B)\n",
    "\n",
    "# Create a Compare object\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches for pairs of date_of_birth and state\n",
    "compare_cl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "compare_cl.exact('state', 'state', label='state')\n",
    "\n",
    "# Find similar matches for pairs of surname and address_1 using string similarity\n",
    "compare_cl.string('surname', 'surname', threshold=0.85, label='surname')\n",
    "compare_cl.string('address_1', 'address_1', threshold=0.85, label='address_1')\n",
    "\n",
    "# Find matches\n",
    "potential_matches = compare_cl.compute(pairs, census_A, census_B)\n",
    "\n",
    "# Isolate matches with matching values for 3 or more columns\n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "\n",
    "# Get index for matching census_B rows only\n",
    "duplicate_rows = matches.index.get_level_values(1)\n",
    "\n",
    "# Finding new rows in census_B\n",
    "census_B_new = census_B[~census_B.index.isin(duplicate_rows)]\n",
    "\n",
    "# Link the DataFrames!\n",
    "full_census = census_A.append(census_B_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo com Dataframe que está neste notebook\n",
    "\n",
    "# Import recordlinkage and generate full pairs\n",
    "import recordlinkage\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Importing DataFrame\n",
    "restaurants = pd.read_csv('restaurants_L2_dirty')\n",
    "restaurants_new = pd.read_csv('restaurants_L2')\n",
    "\n",
    "indexer.block('state')\n",
    "full_pairs = indexer.index(restaurants, restaurants_new)\n",
    "\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types \n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label = 'cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('rest_name', 'rest_name', label='name', threshold = 0.8) \n",
    "\n",
    "# Get potential matches and print\n",
    "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new)\n",
    "print(potential_matches)\n",
    "\n",
    "# Isolate matches with matching values for 3 or more columns\n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "\n",
    "# Get index for matching census_B rows only\n",
    "duplicate_rows = matches.index.get_level_values(1)\n",
    "\n",
    "# Finding new rows in census_B\n",
    "census_B_new = restaurants_new[~restaurants_new.index.isin(duplicate_rows)]\n",
    "\n",
    "# Link the DataFrames!\n",
    "full_restaurants = restaurants.append(restaurants_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
